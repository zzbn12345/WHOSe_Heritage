{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying OUV using Word Embedding and MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/miniconda3/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer('spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.7.0\n",
      "GPU-enabled installation? False\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"GPU-enabled installation? {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "                \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        \n",
    "        Args:\n",
    "            tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "            indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuvVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, ouv_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_vocab (Vocabulary): maps words to integers\n",
    "        \"\"\"\n",
    "        self.ouv_vocab = ouv_vocab\n",
    "        \n",
    "    def vectorize(self, data, vector_length = -1):\n",
    "        \"\"\"Create a collapsed one-hit vector for the ouv data\n",
    "        \n",
    "        Args:\n",
    "            data (str): the ouv description data\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        Returns:\n",
    "            the vectorized data (np.ndarray)\n",
    "        \"\"\"\n",
    "        indices = []\n",
    "        indices.extend(self.ouv_vocab.lookup_token(token) for token in data.split(' '))\n",
    "        \n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "            \n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.ouv_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, ouv_df, cutoff=5):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            ouv_df (pandas.DataFrame): the ouv dataset\n",
    "            cutoff (int): the parameter for frequency-based filtering\n",
    "        Returns:\n",
    "            an instance of the OuvVectorizer\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add top words if count > provided count\n",
    "        word_counts = Counter()\n",
    "        for data in ouv_df.data:\n",
    "            for word in data.split(' '):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "        \n",
    "        ouv_vocab = SequenceVocabulary()\n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                ouv_vocab.add_token(word)\n",
    "\n",
    "        return cls(ouv_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"Instantiate a OuvVectorizer from a serializable dictionary\n",
    "        \n",
    "        Args:\n",
    "            contents (dict): the serializable dictionary\n",
    "        Returns:\n",
    "            an instance of the OuvVectorizer class\n",
    "        \"\"\"\n",
    "        ouv_vocab = SequenceVocabulary.from_serializable(contents['ouv_vocab'])\n",
    "        \n",
    "        return cls(ouv_vocab=ouv_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\"Create the serializable dictionary for caching\n",
    "        \n",
    "        Returns:\n",
    "            contents (dict): the serializable dictionary\n",
    "        \"\"\"\n",
    "        return {'ouv_vocab': self.ouv_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuvDataset(Dataset):\n",
    "    def __init__(self, ouv_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ouv_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
    "        \"\"\"\n",
    "        self.ouv_df = ouv_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        # +0 if not using begin_seq and end seq, +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, ouv_df.data)) + 0\n",
    "\n",
    "        self.train_df = self.ouv_df[self.ouv_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.ouv_df[self.ouv_df.split=='dev']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.ouv_df[self.ouv_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, ouv_csv, cutoff):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            ouv_csv (str): location of the dataset\n",
    "            cutoff (int): the boundary to set the words into unknown\n",
    "        Returns:\n",
    "            an instance of OuvDataset\n",
    "        \"\"\"\n",
    "        ouv_df = pd.read_csv(ouv_csv)\n",
    "        train_ouv_df = ouv_df[ouv_df.split=='train']\n",
    "        return cls(ouv_df, OuvVectorizer.from_dataframe(train_ouv_df, cutoff=cutoff))\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, ouv_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            ouv_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of OuvDataset\n",
    "        \"\"\"\n",
    "        ouv_df = pd.read_csv(ouv_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(ouv_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return OuvVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
    "        \n",
    "        Args:\n",
    "            split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and component for labels (y_target and y_fuzzy)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        ouv_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.data, self._max_seq_length)\n",
    "\n",
    "        true_label = \\\n",
    "            np.fromstring(row.true[1:-1],dtype=float, sep=' ')\n",
    "        \n",
    "        if len(true_label)==10:\n",
    "            true_label = np.append(true_label,0.0)\n",
    "        \n",
    "        fuzzy_label = \\\n",
    "            np.fromstring(row.fuzzy[1:-1],dtype=float, sep=' ')\n",
    "\n",
    "        return {'x_data': ouv_vector,\n",
    "                'y_target': true_label,\n",
    "                'y_fuzzy': fuzzy_label,\n",
    "                'x_length': vec_length\n",
    "               }\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size  \n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: Bag_of_Meaning_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoMClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, num_embeddings, hidden_dim, num_classes, dropout_p, \n",
    "                 pretrained_embeddings=None, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): size of the embedding vectors\n",
    "            num_embeddings (int): number of embedding vectors\n",
    "            hidden_dim (int): the size of the hidden dimension\n",
    "            num_classes (int): the number of classes in classification\n",
    "            dropout_p (float): a dropout parameter \n",
    "            pretrained_embeddings (numpy.array): previously trained word embeddings\n",
    "                default is None. If provided, \n",
    "            padding_idx (int): an index representing a null position\n",
    "        \"\"\"\n",
    "        super(BoMClassifier, self).__init__()\n",
    "\n",
    "        if pretrained_embeddings is None:\n",
    "\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "                                    num_embeddings=num_embeddings,\n",
    "                                    padding_idx=padding_idx)        \n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding.from_pretrained(pretrained_embeddings,\n",
    "                                    padding_idx=padding_idx,\n",
    "                                    freeze=False)\n",
    "        \n",
    "        self._dropout_p = dropout_p\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.padding_idx = padding_idx\n",
    "        #self.prelu = nn.PReLU()\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.fc0 = nn.Linear(embedding_size, num_classes)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, dataset._max_seq_length)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, num_classes)\n",
    "        \"\"\"\n",
    "        \n",
    "        # embed and permute so features are channels\n",
    "        x_embedded = self.emb(x_in)\n",
    "        \n",
    "        padding_mask = x_in.eq(self.padding_idx)\n",
    "        length = (~padding_mask).sum(dim=1)\n",
    "        x_embedded = x_embedded.sum(dim=1)/(length.view(x_embedded.shape[0],1))\n",
    "\n",
    "        # mlp classifier\n",
    "        #intermediate_vector = F.relu(F.dropout(self.fc1(x_embedded), p=self._dropout_p))\n",
    "        #prediction_vector = self.fc2(intermediate_vector)\n",
    "\n",
    "        # logistic regression\n",
    "        intermediate_vector = F.relu(self.dropout(self.fc1(x_embedded)))\n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_k_acc_val': 0,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_1_acc': [],\n",
    "            'train_k_acc': [],\n",
    "            'train_k_jac': [],\n",
    "            'val_loss': [],\n",
    "            'val_1_acc': [],\n",
    "            'val_k_acc': [],\n",
    "            'val_k_jac': [],\n",
    "            'test_loss': -1,\n",
    "            'test_1_acc': -1,\n",
    "            'test_k_acc':-1,\n",
    "            'test_k_jac':-1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        acc_tm1, acc_t = train_state['val_k_acc'][-2:]\n",
    "\n",
    "        # If accuracy worsened\n",
    "        if acc_t <= train_state['early_stopping_best_k_acc_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model from sklearn\n",
    "            if acc_t > train_state['early_stopping_best_k_acc_val']:\n",
    "                train_state['early_stopping_best_k_acc_val'] = acc_t\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                \n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy(y_pred, y_target):\n",
    "    y_target = y_target.cpu().float()\n",
    "    y_pred = y_pred.cpu().float()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    return criterion(y_target, y_pred)\n",
    "\n",
    "def compute_1_accuracy(y_pred, y_target):\n",
    "    y_target_indices = y_target.max(dim=1)[1]\n",
    "    y_pred_indices = y_pred.max(dim=1)[1]\n",
    "    n_correct = torch.eq(y_pred_indices, y_target_indices).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "\n",
    "def compute_k_accuracy(y_pred, y_target, k=3):\n",
    "    y_pred_indices = y_pred.topk(k, dim=1)[1]\n",
    "    y_target_indices = y_target.max(dim=1)[1]\n",
    "    n_correct = torch.tensor([y_pred_indices[i] in y_target_indices[i] for i in range(len(y_pred))]).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "\n",
    "def compute_k_jaccard_index(y_pred, y_target, k=3):\n",
    "    y_target_indices = y_target.topk(k, dim=1)[1]\n",
    "    y_pred_indices = y_pred.max(dim=1)[1]\n",
    "    jaccard = torch.tensor([len(np.intersect1d(y_target_indices[i], y_pred_indices[i]))/\n",
    "                            len(np.union1d(y_target_indices[i], y_pred_indices[i]))\n",
    "                            for i in range(len(y_pred))]).sum().item()\n",
    "    return jaccard / len(y_pred_indices)\n",
    "\n",
    "def compute_jaccard_index(y_pred, y_target, k=3, multilabel=False):\n",
    "    \n",
    "    threshold = 1.0/(k+1)\n",
    "    threshold_2 = 0.5\n",
    "    \n",
    "    if multilabel:\n",
    "        y_pred_indices = y_pred.gt(threshold_2)\n",
    "    else:\n",
    "        y_pred_indices = y_pred.gt(threshold)\n",
    "    \n",
    "    y_target_indices = y_target.gt(threshold)\n",
    "        \n",
    "    jaccard = ((y_target_indices*y_pred_indices).sum(axis=1)/((y_target_indices+y_pred_indices).sum(axis=1)+1e-8)).sum().item()\n",
    "    return jaccard / len(y_pred_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_sensitive(T):\n",
    "    T = np.exp(T) - np.exp(0) + 1e-9\n",
    "    if len(T.shape)==1:\n",
    "        return T/T.sum()\n",
    "    return  T/(T.sum(axis=1).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred, soft_targets):\n",
    "    logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    return torch.mean(torch.sum(- soft_targets * logsoftmax(pred), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fuzzy_label(y_target, y_fuzzy, fuzzy=False, how='uni', lbd=0):\n",
    "    '''\n",
    "    Using two sets of prediction labels and fuzziness parameters to compute the fuzzy label in the form as \n",
    "    a distribution over classes\n",
    "    \n",
    "    Args:\n",
    "    y_target (torch.Tensor) of shape (n_batch, n_classes): the true label of the ouv description\n",
    "    y_fuzzy (torch.Tensor) of shape (n_batch, n_classes): the fuzzy label of the ouv description\n",
    "    fuzzy (bool): whether or not to turn on the fuzziness option\n",
    "    how (string): the way fuzziness weights are used, one of the options in {'uni', 'prior'}\n",
    "    lbd (float): the scaler applied to the fuzziness of the label\n",
    "    \n",
    "    Returns:\n",
    "    A pytorch Tensor of shape (n_batch, n_classes): The processed label in the form of distribution that add to 1\n",
    "    '''\n",
    "    assert y_target.shape == y_fuzzy.shape, 'target labels must have the same size'\n",
    "    assert how in {'uni', 'prior', 'origin'}, '''how must be one of the two options in {'uni', 'prior'}'''\n",
    "    \n",
    "    if not fuzzy:\n",
    "        return softmax_sensitive(y_target)\n",
    "    \n",
    "    if how == 'uni':\n",
    "        y_label = y_target + lbd * y_fuzzy\n",
    "        return softmax_sensitive(y_label)\n",
    "    \n",
    "    ### TO DO ###\n",
    "    elif how == 'prior':\n",
    "        prior = get_prior()\n",
    "        y_inter = torch.matmul(y_target.float(),prior)\n",
    "        y_inter = y_inter/(y_inter.max(dim=1, keepdim=True)[0])\n",
    "        y_label = y_target + lbd * y_fuzzy * y_inter\n",
    "        return softmax_sensitive(y_label)\n",
    "    \n",
    "    else:\n",
    "        y_label = y_target + lbd\n",
    "        return softmax_sensitive(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = args.device\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior():\n",
    "    prior = pd.read_csv(args.prior_csv,sep=';',names=classes[:-1], skiprows=1)\n",
    "    prior['Others'] = 1\n",
    "    prior = prior.T\n",
    "    prior['Others'] = 1\n",
    "    prior = df_to_tensor(prior)\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def load_glove_from_file(glove_filepath):\n",
    "    \"\"\"\n",
    "    Load the GloVe embeddings \n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): path to the glove embeddings file \n",
    "    Returns:\n",
    "        word_to_index (dict), embeddings (numpy.ndarary)\n",
    "    \"\"\"\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "    \"\"\"\n",
    "    Create embedding matrix for a specific set of words.\n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): file path to the glove embeddigns\n",
    "        words (list): list of words in the dataset\n",
    "    \"\"\"\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and Some Prep Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/boe/vectorizer.json\n",
      "\tmodel_storage/boe/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path information\n",
    "    frequency_cutoff=1,\n",
    "    model_state_file='model.pth',\n",
    "    ouv_csv='Data/ouv_with_splits_full.csv',\n",
    "    #ouv_csv='Data/all_with_splits_full.csv',\n",
    "    prior_csv = 'Data/Coappearance_matrix.csv',\n",
    "    save_dir='model_storage/boe/',\n",
    "    vectorizer_file='vectorizer.json',\n",
    "    # Model hyper parameters\n",
    "    glove_filepath='Data/glove/glove.6B.300d.txt', \n",
    "    use_glove=True,\n",
    "    embedding_size=300, \n",
    "    hidden_dim=200, \n",
    "    # Training hyper parameters\n",
    "    batch_size=64,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.0005,\n",
    "    l2=1e-5,\n",
    "    dropout_p=0.1,\n",
    "    k = 3,\n",
    "    fuzzy = True,\n",
    "    fuzzy_how = 'prior',\n",
    "    fuzzy_lambda = 0.01,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "    # Runtime options\n",
    "    catch_keyboard_interrupt=True,\n",
    "    cuda=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    reload_from_files=False,\n",
    ")\n",
    "\n",
    "classes = ['Criteria i', 'Criteria ii', 'Criteria iii', 'Criteria iv', 'Criteria v', 'Criteria vi', \n",
    "              'Criteria vii', 'Criteria viii', 'Criteria ix', 'Criteria x', 'Others']\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained embeddings\n"
     ]
    }
   ],
   "source": [
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "if args.reload_from_files:\n",
    "    # training from a checkpoint\n",
    "    dataset = OuvDataset.load_dataset_and_load_vectorizer(args.ouv_csv, args.vectorizer_file)\n",
    "\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = OuvDataset.load_dataset_and_make_vectorizer(args.ouv_csv, cutoff=args.frequency_cutoff)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)    \n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Use GloVe or randomly initialized embeddings\n",
    "if args.use_glove:\n",
    "    words = vectorizer.ouv_vocab._token_to_idx.keys()\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None\n",
    "\n",
    "classifier = BoMClassifier(embedding_size=args.embedding_size, \n",
    "                            num_embeddings=len(vectorizer.ouv_vocab),\n",
    "                            hidden_dim=args.hidden_dim, \n",
    "                            num_classes=len(classes), \n",
    "                            dropout_p=args.dropout_p,\n",
    "                            pretrained_embeddings=embeddings,\n",
    "                            padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6047, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 LS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.save_dir+'hyperdict_fuzzy.p', 'rb') as fp:\n",
    "    hyperdict_fuzzy = pickle.load(fp)\n",
    "    train_state = hyperdict_fuzzy[('prior',0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoMClassifier(\n",
       "  (emb): Embedding(6047, 300, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=11, bias=True)\n",
       "  (fc0): Linear(in_features=300, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.load_state_dict(torch.load(args.save_dir+'1337/model.pth',map_location=torch.device('cpu')))\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 Baseline w/o LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.save_dir+'hyperdict_fuzzy.p', 'rb') as fp:\n",
    "    hyperdict_fuzzy = pickle.load(fp)\n",
    "    train_state = hyperdict_fuzzy[('uni',0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoMClassifier(\n",
       "  (emb): Embedding(6047, 300, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=11, bias=True)\n",
       "  (fc0): Linear(in_features=300, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.load_state_dict(torch.load(args.save_dir+'baseline/model.pth',map_location=torch.device('cpu')))\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1879822"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "loss_func = cross_entropy\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_1_acc = 0.\n",
    "running_k_acc = 0.\n",
    "running_k_jac = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    \n",
    "    # get the data compute fuzzy labels\n",
    "    X = batch_dict['x_data']\n",
    "\n",
    "    y_target = batch_dict['y_target']\n",
    "    y_fuzzy = batch_dict['y_fuzzy']\n",
    "\n",
    "    Y = compute_fuzzy_label(y_target, y_fuzzy, fuzzy= args.fuzzy, \n",
    "                            how=args.fuzzy_how, lbd = args.fuzzy_lambda)\n",
    "\n",
    "    # compute the output\n",
    "    y_pred = classifier(X)\n",
    "\n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, Y)\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_1_t = compute_1_accuracy(y_pred, y_target)\n",
    "    acc_k_t = compute_k_accuracy(y_pred, y_target, args.k)\n",
    "    jac_k_t = compute_jaccard_index(y_pred, y_target, args.k)\n",
    "\n",
    "    running_1_acc += (acc_1_t - running_1_acc) / (batch_index + 1)\n",
    "    running_k_acc += (acc_k_t - running_k_acc) / (batch_index + 1)\n",
    "    running_k_jac += (jac_k_t - running_k_jac) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_1_acc'] = running_1_acc\n",
    "train_state['test_k_acc'] = running_k_acc\n",
    "train_state['test_k_jac'] = running_k_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': True,\n",
       " 'early_stopping_step': 5,\n",
       " 'early_stopping_best_k_acc_val': 91.6015625,\n",
       " 'learning_rate': 0.0005,\n",
       " 'epoch_index': 14,\n",
       " 'train_loss': [2.1898845044639987,\n",
       "  1.826476272113359,\n",
       "  1.559559585745376,\n",
       "  1.3866063025736874,\n",
       "  1.2408114981223686,\n",
       "  1.113574092728647,\n",
       "  0.9993298727031326,\n",
       "  0.8972375632932136,\n",
       "  0.8103033107871556,\n",
       "  0.7333694549326527,\n",
       "  0.6681834909475741,\n",
       "  0.6052449256315965,\n",
       "  0.5544813637422835,\n",
       "  0.5023667965405726,\n",
       "  0.47651820728788274],\n",
       " 'train_1_acc': [24.375,\n",
       "  32.47767857142856,\n",
       "  41.18303571428573,\n",
       "  49.19642857142857,\n",
       "  55.51339285714287,\n",
       "  61.02678571428571,\n",
       "  66.3392857142857,\n",
       "  71.2276785714286,\n",
       "  73.63839285714286,\n",
       "  76.89732142857142,\n",
       "  78.92857142857144,\n",
       "  81.96428571428571,\n",
       "  83.77232142857143,\n",
       "  85.62499999999999,\n",
       "  86.65178571428572],\n",
       " 'train_k_acc': [55.02232142857142,\n",
       "  69.64285714285715,\n",
       "  77.83482142857144,\n",
       "  84.1964285714286,\n",
       "  89.375,\n",
       "  92.56696428571429,\n",
       "  93.4598214285714,\n",
       "  94.97767857142858,\n",
       "  96.3169642857143,\n",
       "  96.96428571428574,\n",
       "  97.67857142857142,\n",
       "  98.14732142857149,\n",
       "  98.57142857142857,\n",
       "  98.92857142857142,\n",
       "  99.19642857142857],\n",
       " 'train_k_jac': [0.15329135039022995,\n",
       "  0.19133388378790447,\n",
       "  0.20485411243779322,\n",
       "  0.20747980879885805,\n",
       "  0.21707961857318875,\n",
       "  0.22720238587685992,\n",
       "  0.23916666954755786,\n",
       "  0.2521837853959628,\n",
       "  0.26525669864245827,\n",
       "  0.2789211371115276,\n",
       "  0.28193080851009905,\n",
       "  0.2932105737073079,\n",
       "  0.29924107832568025,\n",
       "  0.30741444400378626,\n",
       "  0.31228423586913523],\n",
       " 'val_loss': [2.0393798770938703,\n",
       "  1.7147178651119266,\n",
       "  1.5316279368080084,\n",
       "  1.3866451245858777,\n",
       "  1.2972420956979944,\n",
       "  1.1781756002418455,\n",
       "  1.1244210706840396,\n",
       "  1.0755305094380965,\n",
       "  1.0030664637764568,\n",
       "  1.0339486685415884,\n",
       "  0.9804892168994296,\n",
       "  1.0268704795638428,\n",
       "  1.0360664683553762,\n",
       "  1.0226672736633238,\n",
       "  1.0206896860177872],\n",
       " 'val_1_acc': [29.6875,\n",
       "  34.765625,\n",
       "  40.62499999999999,\n",
       "  52.734375,\n",
       "  51.953125,\n",
       "  59.5703125,\n",
       "  60.3515625,\n",
       "  61.5234375,\n",
       "  67.1875,\n",
       "  64.2578125,\n",
       "  65.234375,\n",
       "  63.47656250000001,\n",
       "  64.84375,\n",
       "  66.015625,\n",
       "  65.0390625],\n",
       " 'val_k_acc': [60.3515625,\n",
       "  70.8984375,\n",
       "  75.390625,\n",
       "  81.8359375,\n",
       "  85.15625,\n",
       "  88.8671875,\n",
       "  88.28125,\n",
       "  88.671875,\n",
       "  91.2109375,\n",
       "  91.6015625,\n",
       "  91.40625,\n",
       "  90.4296875,\n",
       "  90.625,\n",
       "  90.8203125,\n",
       "  91.2109375],\n",
       " 'val_k_jac': [0.16051199845969677,\n",
       "  0.19462425261735916,\n",
       "  0.20143230259418485,\n",
       "  0.2052734438329935,\n",
       "  0.21315104328095913,\n",
       "  0.23593750037252903,\n",
       "  0.23860677890479565,\n",
       "  0.25843099504709244,\n",
       "  0.2597981858998537,\n",
       "  0.2607421875,\n",
       "  0.26888021454215044,\n",
       "  0.2695963568985462,\n",
       "  0.2740234434604645,\n",
       "  0.2740885429084301,\n",
       "  0.28219401463866234],\n",
       " 'test_loss': 1.0354947958658398,\n",
       " 'test_1_acc': 62.6953125,\n",
       " 'test_k_acc': 91.40625,\n",
       " 'test_k_jac': 0.2674479298293591,\n",
       " 'model_filename': 'model_storage/bom/mlp/multigroup/model.pth'}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LS Model\n",
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': True,\n",
       " 'early_stopping_step': 5,\n",
       " 'early_stopping_best_k_acc_val': 91.9921875,\n",
       " 'learning_rate': 0.0005,\n",
       " 'epoch_index': 20,\n",
       " 'train_loss': [2.190541874143522,\n",
       "  1.8252948762847738,\n",
       "  1.5550043664696633,\n",
       "  1.3797261274516228,\n",
       "  1.2345890146896672,\n",
       "  1.1075645811739887,\n",
       "  0.9936930913616233,\n",
       "  0.8895259621350297,\n",
       "  0.800876014547145,\n",
       "  0.721189041433437,\n",
       "  0.6540138013945365,\n",
       "  0.5883709579798869,\n",
       "  0.5356499633452085,\n",
       "  0.4818158328835293,\n",
       "  0.4556607222038697,\n",
       "  0.42846638480195387,\n",
       "  0.4227904006249722,\n",
       "  0.40677541047246585,\n",
       "  0.39836683752281554,\n",
       "  0.3980314026501697,\n",
       "  0.39684097303629856],\n",
       " 'train_1_acc': [24.129464285714285,\n",
       "  32.61160714285713,\n",
       "  41.45089285714288,\n",
       "  48.97321428571428,\n",
       "  55.31250000000001,\n",
       "  60.825892857142854,\n",
       "  66.04910714285715,\n",
       "  71.11607142857146,\n",
       "  73.37053571428575,\n",
       "  76.20535714285714,\n",
       "  78.70535714285714,\n",
       "  81.65178571428572,\n",
       "  83.61607142857143,\n",
       "  85.35714285714289,\n",
       "  86.09374999999997,\n",
       "  87.41071428571428,\n",
       "  87.70089285714286,\n",
       "  88.05803571428572,\n",
       "  88.54910714285712,\n",
       "  88.23660714285712,\n",
       "  88.50446428571428],\n",
       " 'train_k_acc': [54.70982142857142,\n",
       "  69.41964285714285,\n",
       "  77.87946428571429,\n",
       "  84.3526785714286,\n",
       "  89.24107142857143,\n",
       "  92.45535714285715,\n",
       "  93.37053571428568,\n",
       "  94.82142857142857,\n",
       "  96.1160714285714,\n",
       "  96.83035714285712,\n",
       "  97.38839285714286,\n",
       "  97.90178571428575,\n",
       "  98.37053571428567,\n",
       "  98.77232142857137,\n",
       "  99.10714285714286,\n",
       "  99.04017857142861,\n",
       "  99.01785714285714,\n",
       "  99.15178571428571,\n",
       "  99.10714285714286,\n",
       "  99.17410714285714,\n",
       "  99.04017857142857],\n",
       " 'train_k_jac': [0.15329666499580658,\n",
       "  0.19090844861098702,\n",
       "  0.20436623011316568,\n",
       "  0.2080899270517485,\n",
       "  0.21746652211461753,\n",
       "  0.2275446459650993,\n",
       "  0.23899925968476707,\n",
       "  0.2521354238901819,\n",
       "  0.26440104586737506,\n",
       "  0.2790550634264947,\n",
       "  0.2823325940540859,\n",
       "  0.29309896443571365,\n",
       "  0.29990328167166036,\n",
       "  0.3090029839958464,\n",
       "  0.3139137008360455,\n",
       "  0.31422248014381965,\n",
       "  0.31759301338877,\n",
       "  0.3205022377627237,\n",
       "  0.3214657826083047,\n",
       "  0.3223698024238858,\n",
       "  0.3220014968088695],\n",
       " 'val_loss': [2.039805804796545,\n",
       "  1.711911033978763,\n",
       "  1.5263594524130109,\n",
       "  1.3809972128705654,\n",
       "  1.292577947638935,\n",
       "  1.174519428417788,\n",
       "  1.1208718254510106,\n",
       "  1.0693951977628329,\n",
       "  0.9951275863331908,\n",
       "  1.0235008037827715,\n",
       "  0.9697423447362696,\n",
       "  1.0165901933607882,\n",
       "  1.025753583407329,\n",
       "  1.0121256363446078,\n",
       "  1.0102985213847586,\n",
       "  1.0048683212091987,\n",
       "  0.9999817758243401,\n",
       "  1.0016832014377888,\n",
       "  1.0452823222063001,\n",
       "  1.0260860288721816,\n",
       "  1.0040879471941893],\n",
       " 'val_1_acc': [28.90625,\n",
       "  34.5703125,\n",
       "  40.23437500000001,\n",
       "  52.9296875,\n",
       "  52.1484375,\n",
       "  59.5703125,\n",
       "  60.3515625,\n",
       "  61.71875,\n",
       "  66.796875,\n",
       "  64.6484375,\n",
       "  65.234375,\n",
       "  63.47656250000001,\n",
       "  64.64843750000001,\n",
       "  66.2109375,\n",
       "  64.84375,\n",
       "  65.0390625,\n",
       "  65.234375,\n",
       "  65.0390625,\n",
       "  63.671875,\n",
       "  65.23437500000001,\n",
       "  65.4296875],\n",
       " 'val_k_acc': [59.9609375,\n",
       "  70.8984375,\n",
       "  76.171875,\n",
       "  81.8359375,\n",
       "  85.546875,\n",
       "  88.671875,\n",
       "  88.28125,\n",
       "  88.28125,\n",
       "  91.2109375,\n",
       "  91.40625,\n",
       "  91.796875,\n",
       "  90.4296875,\n",
       "  91.015625,\n",
       "  90.8203125,\n",
       "  90.8203125,\n",
       "  91.9921875,\n",
       "  90.8203125,\n",
       "  91.79687499999999,\n",
       "  90.625,\n",
       "  91.6015625,\n",
       "  91.2109375],\n",
       " 'val_k_jac': [0.15902157686650753,\n",
       "  0.1950334757566452,\n",
       "  0.20179037563502789,\n",
       "  0.20634766295552254,\n",
       "  0.214225260540843,\n",
       "  0.23512370139360428,\n",
       "  0.23893229477107525,\n",
       "  0.25865885242819786,\n",
       "  0.25970052368938923,\n",
       "  0.26113281585276127,\n",
       "  0.26793620362877846,\n",
       "  0.2670898474752903,\n",
       "  0.2736979275941849,\n",
       "  0.27294921875,\n",
       "  0.28095703199505806,\n",
       "  0.28333333507180214,\n",
       "  0.28268229961395264,\n",
       "  0.2859700582921505,\n",
       "  0.2840169370174408,\n",
       "  0.28658855333924294,\n",
       "  0.2907552160322666],\n",
       " 'test_loss': 1.066745860225489,\n",
       " 'test_1_acc': 62.109375,\n",
       " 'test_k_acc': 91.6015625,\n",
       " 'test_k_jac': 0.295345064252615,\n",
       " 'model_filename': 'model_storage/bom/mlp/multigroup/model.pth'}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(text, classifier, vectorizer, classes, k=1):\n",
    "    \"\"\"Predict the rating of a review\n",
    "    \n",
    "    Args:\n",
    "        text (str): the text of the description\n",
    "        classifier (ReviewClassifier): the trained model\n",
    "        vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
    "        classes (list of str): The name of the ouv classes\n",
    "        k (int): show the largest k prediction, default to 1\n",
    "    \"\"\"\n",
    "    ouv = preprocess_text(text)\n",
    "    \n",
    "    vectorized_ouv = torch.tensor(vectorizer.vectorize(ouv)[0])\n",
    "    X = vectorized_ouv.view(1,-1)\n",
    "    result = classifier(vectorized_ouv.unsqueeze(0), apply_softmax=True)\n",
    "    \n",
    "    if k==1:\n",
    "        pred_id = result.argmax().item()\n",
    "        return (classes[pred_id], result[0][pred_id])\n",
    "    else:\n",
    "        pred_indices = [i.item() for i in result.topk(k)[1][0]]\n",
    "        output = []\n",
    "        for pred_id in pred_indices:\n",
    "            output.append((classes[pred_id],result[0][pred_id].item()))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a very old building dating back to 13th century -> Criteria iv with a probability of 0.74\n"
     ]
    }
   ],
   "source": [
    "test_ouv = 'this is a very old building dating back to 13th century'\n",
    "\n",
    "prediction = predict_rating(test_ouv,classifier,vectorizer,classes)\n",
    "print('{} -> {} with a probability of {:0.2f}'.format(test_ouv, prediction[0],prediction[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions:\n",
      "===================\n",
      "this is a very old building dating back to 13th century -> Criteria iv with a probability of 0.74\n",
      "this is a very old building dating back to 13th century -> Criteria iii with a probability of 0.16\n",
      "this is a very old building dating back to 13th century -> Criteria i with a probability of 0.04\n"
     ]
    }
   ],
   "source": [
    "test_ouv = 'this is a very old building dating back to 13th century'\n",
    "k=3\n",
    "predictions = predict_rating(test_ouv,classifier,vectorizer,classes,k)\n",
    "\n",
    "print(\"Top {} predictions:\".format(k))\n",
    "print(\"===================\")\n",
    "for prediction in predictions:\n",
    "    print('{} -> {} with a probability of {:0.2f}'.format(test_ouv, prediction[0],prediction[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions:\n",
      "===================\n",
      "The particular layout of the complex is unique to this site -> Criteria iv with a probability of 0.45\n",
      "The particular layout of the complex is unique to this site -> Criteria i with a probability of 0.17\n",
      "The particular layout of the complex is unique to this site -> Criteria v with a probability of 0.16\n"
     ]
    }
   ],
   "source": [
    "test_ouv = 'The particular layout of the complex is unique to this site'\n",
    "k=3\n",
    "predictions = predict_rating(test_ouv,classifier,vectorizer,classes,k)\n",
    "\n",
    "print(\"Top {} predictions:\".format(k))\n",
    "print(\"===================\")\n",
    "for prediction in predictions:\n",
    "    print('{} -> {} with a probability of {:0.2f}'.format(test_ouv, prediction[0],prediction[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0.0006792545318603516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Timer(object):\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.tstart = time.time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.name:\n",
    "            print('[%s]' % self.name,)\n",
    "        print('Elapsed: %s' % (time.time() - self.tstart))\n",
    "        \n",
    "set_seed_everywhere(args.seed, args.cuda)        \n",
    "test_ouv = 'The particular layout of the complex is unique to this site'\n",
    "k=3\n",
    "with Timer():\n",
    "    predictions = predict_rating(test_ouv,classifier,vectorizer,classes,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_iterator(token_list, ngrams):\n",
    "    def _get_ngrams(n):\n",
    "        return zip(*[token_list[i:] for i in range(n)])\n",
    "    for x in token_list:\n",
    "        yield x\n",
    "    for n in range(2, ngrams+1):\n",
    "        for x in _get_ngrams(n):\n",
    "            yield ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouv_df = pd.read_csv(args.ouv_csv)\n",
    "word_counts = Counter()\n",
    "for data in ouv_df.data:\n",
    "    token_list = data.split(' ')\n",
    "    for word in ngrams_iterator(token_list, 5):\n",
    "        temp = 0\n",
    "        for element in word:\n",
    "            if element in string.punctuation:\n",
    "                temp = 1\n",
    "                break\n",
    "        if temp==0:\n",
    "            word_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2353"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [word for word, count in word_counts.items() if count>15 and count<600]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tokens_importance(vocab, classifier, vectorizer, classes, k=50):\n",
    "    \"\"\"Predict the rating of a review\n",
    "    \n",
    "    Args:\n",
    "        vocab (list of str): the whole vocabulary\n",
    "        classifier (ReviewClassifier): the trained model\n",
    "        vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
    "        classes (list of str): The name of the ouv classes\n",
    "        k (int): show the largest k prediction, default to 1\n",
    "    \"\"\"\n",
    "    vectorized_token = []    \n",
    "    for token in vocab:\n",
    "        vectorized_token.append(torch.tensor(vectorizer.vectorize(token, vector_length=dataset._max_seq_length)[0]))\n",
    "    \n",
    "    result=torch.zeros((int(len(vocab)/args.batch_size)+1)*args.batch_size,len(classes))\n",
    "    #print(result.shape)\n",
    "    for i in range(int(len(vocab)/args.batch_size)+1):\n",
    "        X = torch.stack(vectorized_token[i*args.batch_size:(i+1)*args.batch_size])\n",
    "        X = torch.cat([X,torch.zeros(args.batch_size-X.shape[0], dataset._max_seq_length).long()])\n",
    "        #print(X.shape)\n",
    "        classifier.eval()\n",
    "        res = classifier(X,apply_softmax=True)\n",
    "        #print(res.shape)\n",
    "        result[i*args.batch_size:(i+1)*args.batch_size]=res\n",
    "        #print(result.shape)\n",
    "    result = result[:len(vocab)]\n",
    "    \n",
    "    vocab_id = result[1:].topk(k, dim=0)[1]\n",
    "    vocab_weight = result[1:].topk(k, dim=0)[0]\n",
    "    return vocab_id, vocab_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_k = infer_tokens_importance(vocab, classifier, vectorizer, classes, k=50)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_k = {}\n",
    "for i in range(len(vocab)):\n",
    "    if vocab[i] in vocab_k:\n",
    "        class_k[vocab[i]]={}\n",
    "        class_k[vocab[i]]['idx'] = token_k[vocab[i]]\n",
    "        class_k[vocab[i]]['vocab_id'] = i\n",
    "        class_k[vocab[i]]['class'] = []\n",
    "        for j in range(len(classes)):\n",
    "            if i in all_k[:,j]:\n",
    "                class_k[vocab[i]]['class'].append(classes[j])\n",
    "                if j<6:\n",
    "                    class_k[vocab[i]]['type'] = 'cultural'\n",
    "                elif j<10:\n",
    "                    class_k[vocab[i]]['type'] = 'natural'\n",
    "                else:\n",
    "                    class_k[vocab[i]]['type'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k = pd.DataFrame(class_k).T\n",
    "df_k['n_classes'] = df_k['class'].apply(lambda x: len(x))\n",
    "df_k['label'] = df_k['class'].apply(lambda x: x[0])\n",
    "df_k.reset_index().set_index('idx')[['label','type','index']].to_csv(args.save_dir+'emb_vocab.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2353"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_top_k_DataFrame(vocab, classifier, vectorizer, classes, k=10):\n",
    "    \n",
    "    vocab_id = infer_tokens_importance(vocab, classifier, vectorizer, classes, k)[0]\n",
    "    df = pd.DataFrame(columns = classes)\n",
    "    for i in range(len(classes)):\n",
    "        \n",
    "        indices = vocab_id[:,i].tolist()\n",
    "        words = pd.Series([vocab[j] for j in indices])\n",
    "        df[classes[i]] = words\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criteria i</th>\n",
       "      <th>Criteria ii</th>\n",
       "      <th>Criteria iii</th>\n",
       "      <th>Criteria iv</th>\n",
       "      <th>Criteria v</th>\n",
       "      <th>Criteria vi</th>\n",
       "      <th>Criteria vii</th>\n",
       "      <th>Criteria viii</th>\n",
       "      <th>Criteria ix</th>\n",
       "      <th>Criteria x</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process of</td>\n",
       "      <td>exerted</td>\n",
       "      <td>the site</td>\n",
       "      <td>administrative</td>\n",
       "      <td>cultural landscape of</td>\n",
       "      <td>it was</td>\n",
       "      <td>geological</td>\n",
       "      <td>impressive</td>\n",
       "      <td>is one</td>\n",
       "      <td>critically</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unique artistic</td>\n",
       "      <td>exhibits</td>\n",
       "      <td>monuments</td>\n",
       "      <td>monasteries</td>\n",
       "      <td>remains of</td>\n",
       "      <td>estimated</td>\n",
       "      <td>man</td>\n",
       "      <td>the architecture of</td>\n",
       "      <td>processes</td>\n",
       "      <td>critically endangered</td>\n",
       "      <td>testimony of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a unique artistic</td>\n",
       "      <td>de</td>\n",
       "      <td>provides an</td>\n",
       "      <td>low</td>\n",
       "      <td>over time</td>\n",
       "      <td>directly associated</td>\n",
       "      <td>exceptional natural</td>\n",
       "      <td>changes</td>\n",
       "      <td>zone</td>\n",
       "      <td>bear</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital of the</td>\n",
       "      <td>leading</td>\n",
       "      <td>urban</td>\n",
       "      <td>the palace</td>\n",
       "      <td>of traditional</td>\n",
       "      <td>outstanding universal</td>\n",
       "      <td>trade</td>\n",
       "      <td>basin</td>\n",
       "      <td>remaining</td>\n",
       "      <td>endemic</td>\n",
       "      <td>evolutionary processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contains</td>\n",
       "      <td>more than</td>\n",
       "      <td>monument</td>\n",
       "      <td>royal</td>\n",
       "      <td>reflecting</td>\n",
       "      <td>continuing</td>\n",
       "      <td>unique</td>\n",
       "      <td>this region</td>\n",
       "      <td>geological processes</td>\n",
       "      <td>include the</td>\n",
       "      <td>land use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>represents a</td>\n",
       "      <td>and landscape</td>\n",
       "      <td>itself</td>\n",
       "      <td>and urban</td>\n",
       "      <td>example of</td>\n",
       "      <td>an architectural</td>\n",
       "      <td>altitude</td>\n",
       "      <td>features</td>\n",
       "      <td>endemic to the</td>\n",
       "      <td>also contains</td>\n",
       "      <td>aspects of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overall</td>\n",
       "      <td>than</td>\n",
       "      <td>bears exceptional</td>\n",
       "      <td>colonization</td>\n",
       "      <td>traditions</td>\n",
       "      <td>indigenous</td>\n",
       "      <td>mosaic</td>\n",
       "      <td>example of a type of</td>\n",
       "      <td>what</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>erosion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interior</td>\n",
       "      <td>asia</td>\n",
       "      <td>is home to</td>\n",
       "      <td>examples</td>\n",
       "      <td>was</td>\n",
       "      <td>political</td>\n",
       "      <td>metres</td>\n",
       "      <td>record</td>\n",
       "      <td>and biological</td>\n",
       "      <td>bird</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>masterpiece</td>\n",
       "      <td>an important</td>\n",
       "      <td>economic and</td>\n",
       "      <td>towns</td>\n",
       "      <td>socio</td>\n",
       "      <td>is directly</td>\n",
       "      <td>national</td>\n",
       "      <td>evolution</td>\n",
       "      <td>pacific</td>\n",
       "      <td>plant and</td>\n",
       "      <td>period in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unique artistic achievement</td>\n",
       "      <td>architecture in the</td>\n",
       "      <td>culture of</td>\n",
       "      <td>plant and animal</td>\n",
       "      <td>cultural landscape</td>\n",
       "      <td>and tangibly associated with</td>\n",
       "      <td>rugged</td>\n",
       "      <td>array</td>\n",
       "      <td>ecological</td>\n",
       "      <td>wild</td>\n",
       "      <td>because of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a masterpiece</td>\n",
       "      <td>interchange of</td>\n",
       "      <td>millennium</td>\n",
       "      <td>an outstanding</td>\n",
       "      <td>animals</td>\n",
       "      <td>and tangibly associated</td>\n",
       "      <td>the great</td>\n",
       "      <td>remarkably</td>\n",
       "      <td>level</td>\n",
       "      <td>monumental</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and one of the</td>\n",
       "      <td>important interchange</td>\n",
       "      <td>many of</td>\n",
       "      <td>styles</td>\n",
       "      <td>position</td>\n",
       "      <td>world and</td>\n",
       "      <td>trees</td>\n",
       "      <td>of monuments</td>\n",
       "      <td>changes in</td>\n",
       "      <td>of endemic</td>\n",
       "      <td>immense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>masterpiece of</td>\n",
       "      <td>dynasty</td>\n",
       "      <td>an exceptional testimony</td>\n",
       "      <td>imperial</td>\n",
       "      <td>deciduous</td>\n",
       "      <td>is directly and</td>\n",
       "      <td>underground</td>\n",
       "      <td>succession</td>\n",
       "      <td>ecological and</td>\n",
       "      <td>species include</td>\n",
       "      <td>vascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sculpture</td>\n",
       "      <td>the influence</td>\n",
       "      <td>a landscape</td>\n",
       "      <td>are an outstanding</td>\n",
       "      <td>bronze age</td>\n",
       "      <td>tangibly associated with</td>\n",
       "      <td>constitutes</td>\n",
       "      <td>numbers</td>\n",
       "      <td>series</td>\n",
       "      <td>particularly</td>\n",
       "      <td>sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is a masterpiece</td>\n",
       "      <td>later</td>\n",
       "      <td>bears exceptional testimony</td>\n",
       "      <td>preserved example</td>\n",
       "      <td>of a traditional</td>\n",
       "      <td>scientific</td>\n",
       "      <td>abundant</td>\n",
       "      <td>elsewhere</td>\n",
       "      <td>continued</td>\n",
       "      <td>created</td>\n",
       "      <td>remains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>artistic achievement</td>\n",
       "      <td>adaptation</td>\n",
       "      <td>comprising</td>\n",
       "      <td>related</td>\n",
       "      <td>control</td>\n",
       "      <td>impact</td>\n",
       "      <td>temperate</td>\n",
       "      <td>illustrating</td>\n",
       "      <td>in the development of</td>\n",
       "      <td>open</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>of human creative</td>\n",
       "      <td>and is</td>\n",
       "      <td>history</td>\n",
       "      <td>last</td>\n",
       "      <td>valley</td>\n",
       "      <td>species such as</td>\n",
       "      <td>result of</td>\n",
       "      <td>million</td>\n",
       "      <td>illustrated</td>\n",
       "      <td>his</td>\n",
       "      <td>industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and exceptional</td>\n",
       "      <td>on the development of</td>\n",
       "      <td>urban and architectural</td>\n",
       "      <td>extensive</td>\n",
       "      <td>exchanges</td>\n",
       "      <td>directly and tangibly associated</td>\n",
       "      <td>size</td>\n",
       "      <td>majestic</td>\n",
       "      <td>can be seen</td>\n",
       "      <td>of this</td>\n",
       "      <td>practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decoration</td>\n",
       "      <td>landscape of</td>\n",
       "      <td>culture of the</td>\n",
       "      <td>applied</td>\n",
       "      <td>each</td>\n",
       "      <td>directly</td>\n",
       "      <td>a large</td>\n",
       "      <td>caves</td>\n",
       "      <td>stage</td>\n",
       "      <td>a number</td>\n",
       "      <td>buildings and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decorated</td>\n",
       "      <td>manner</td>\n",
       "      <td>exceptional testimony</td>\n",
       "      <td>the establishment of</td>\n",
       "      <td>provided</td>\n",
       "      <td>together</td>\n",
       "      <td>from its</td>\n",
       "      <td>i</td>\n",
       "      <td>evergreen</td>\n",
       "      <td>and which</td>\n",
       "      <td>across</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Criteria i            Criteria ii  \\\n",
       "0                    process of                exerted   \n",
       "1               unique artistic               exhibits   \n",
       "2             a unique artistic                     de   \n",
       "3                capital of the                leading   \n",
       "4                      contains              more than   \n",
       "5                  represents a          and landscape   \n",
       "6                       overall                   than   \n",
       "7                      interior                   asia   \n",
       "8                   masterpiece           an important   \n",
       "9   unique artistic achievement    architecture in the   \n",
       "10                a masterpiece         interchange of   \n",
       "11               and one of the  important interchange   \n",
       "12               masterpiece of                dynasty   \n",
       "13                    sculpture          the influence   \n",
       "14             is a masterpiece                  later   \n",
       "15         artistic achievement             adaptation   \n",
       "16            of human creative                 and is   \n",
       "17              and exceptional  on the development of   \n",
       "18                   decoration           landscape of   \n",
       "19                    decorated                 manner   \n",
       "\n",
       "                   Criteria iii           Criteria iv             Criteria v  \\\n",
       "0                      the site        administrative  cultural landscape of   \n",
       "1                     monuments           monasteries             remains of   \n",
       "2                   provides an                   low              over time   \n",
       "3                         urban            the palace         of traditional   \n",
       "4                      monument                 royal             reflecting   \n",
       "5                        itself             and urban             example of   \n",
       "6             bears exceptional          colonization             traditions   \n",
       "7                    is home to              examples                    was   \n",
       "8                  economic and                 towns                  socio   \n",
       "9                    culture of      plant and animal     cultural landscape   \n",
       "10                   millennium        an outstanding                animals   \n",
       "11                      many of                styles               position   \n",
       "12     an exceptional testimony              imperial              deciduous   \n",
       "13                  a landscape    are an outstanding             bronze age   \n",
       "14  bears exceptional testimony     preserved example       of a traditional   \n",
       "15                   comprising               related                control   \n",
       "16                      history                  last                 valley   \n",
       "17      urban and architectural             extensive              exchanges   \n",
       "18               culture of the               applied                   each   \n",
       "19        exceptional testimony  the establishment of               provided   \n",
       "\n",
       "                         Criteria vi         Criteria vii  \\\n",
       "0                             it was           geological   \n",
       "1                          estimated                  man   \n",
       "2                directly associated  exceptional natural   \n",
       "3              outstanding universal                trade   \n",
       "4                         continuing               unique   \n",
       "5                   an architectural             altitude   \n",
       "6                         indigenous               mosaic   \n",
       "7                          political               metres   \n",
       "8                        is directly             national   \n",
       "9       and tangibly associated with               rugged   \n",
       "10           and tangibly associated            the great   \n",
       "11                         world and                trees   \n",
       "12                   is directly and          underground   \n",
       "13          tangibly associated with          constitutes   \n",
       "14                        scientific             abundant   \n",
       "15                            impact            temperate   \n",
       "16                   species such as            result of   \n",
       "17  directly and tangibly associated                 size   \n",
       "18                          directly              a large   \n",
       "19                          together             from its   \n",
       "\n",
       "           Criteria viii            Criteria ix             Criteria x  \\\n",
       "0             impressive                 is one             critically   \n",
       "1    the architecture of              processes  critically endangered   \n",
       "2                changes                   zone                   bear   \n",
       "3                  basin              remaining                endemic   \n",
       "4            this region   geological processes            include the   \n",
       "5               features         endemic to the          also contains   \n",
       "6   example of a type of                   what                exhibit   \n",
       "7                 record         and biological                   bird   \n",
       "8              evolution                pacific              plant and   \n",
       "9                  array             ecological                   wild   \n",
       "10            remarkably                  level             monumental   \n",
       "11          of monuments             changes in             of endemic   \n",
       "12            succession         ecological and        species include   \n",
       "13               numbers                 series           particularly   \n",
       "14             elsewhere              continued                created   \n",
       "15          illustrating  in the development of                   open   \n",
       "16               million            illustrated                    his   \n",
       "17              majestic            can be seen                of this   \n",
       "18                 caves                  stage               a number   \n",
       "19                     i              evergreen              and which   \n",
       "\n",
       "                    Others  \n",
       "0                      has  \n",
       "1         testimony of the  \n",
       "2                   public  \n",
       "3   evolutionary processes  \n",
       "4                 land use  \n",
       "5               aspects of  \n",
       "6                  erosion  \n",
       "7                    after  \n",
       "8                period in  \n",
       "9           because of the  \n",
       "10                  united  \n",
       "11                 immense  \n",
       "12                vascular  \n",
       "13                     sub  \n",
       "14                 remains  \n",
       "15               isolation  \n",
       "16                industry  \n",
       "17                practice  \n",
       "18           buildings and  \n",
       "19                  across  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_top_k_DataFrame(vocab, classifier, vectorizer, classes, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_top_k_DataFrame(vocab, classifier, vectorizer, classes, k=50).to_csv(args.save_dir+'top_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('test')\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "conf_mat_test = np.zeros((len(classes)-1,len(classes)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    \n",
    "    # get the data compute fuzzy labels\n",
    "    X = batch_dict['x_data']\n",
    "\n",
    "    y_target = batch_dict['y_target']\n",
    "    y_fuzzy = batch_dict['y_fuzzy']\n",
    "\n",
    "    Y = compute_fuzzy_label(y_target, y_fuzzy, fuzzy= args.fuzzy, \n",
    "                            how=args.fuzzy_how, lbd = args.fuzzy_lambda)\n",
    "\n",
    "    # compute the output\n",
    "    y_pred = classifier(X)\n",
    "    \n",
    "    conf_mat_test = np.add(conf_mat_test,confusion_matrix(y_target.argmax(axis=1), y_pred.argmax(axis=1)\n",
    "                                                          ,labels=range(len(classes)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.,  3.,  4.,  7.,  0.,  3.,  1.,  0.,  0.,  0.],\n",
       "       [ 2., 51.,  5.,  8.,  3.,  3.,  1.,  0.,  1.,  0.],\n",
       "       [ 1.,  4., 37., 12.,  3.,  6.,  0.,  0.,  0.,  0.],\n",
       "       [ 4., 16.,  9., 41.,  7.,  3.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  3.,  9., 13.,  1.,  2.,  0.,  3.,  0.],\n",
       "       [ 0.,  7.,  9.,  1.,  1., 25.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  2.,  0.,  1., 31.,  3.,  1.,  4.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  2.,  6., 18.,  4.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.,  3.,  2., 31.,  9.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  5., 56.]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('val')\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "conf_mat_val = np.zeros((len(classes)-1,len(classes)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    \n",
    "    # get the data compute fuzzy labels\n",
    "    X = batch_dict['x_data']\n",
    "\n",
    "    y_target = batch_dict['y_target']\n",
    "    y_fuzzy = batch_dict['y_fuzzy']\n",
    "\n",
    "    Y = compute_fuzzy_label(y_target, y_fuzzy, fuzzy= args.fuzzy, \n",
    "                            how=args.fuzzy_how, lbd = args.fuzzy_lambda)\n",
    "\n",
    "    # compute the output\n",
    "    y_pred = classifier(X)\n",
    "    \n",
    "    conf_mat_val = np.add(conf_mat_val,confusion_matrix(y_target.argmax(axis=1), y_pred.argmax(axis=1)\n",
    "                                                        ,labels=range(len(classes)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.,  4.,  2., 10.,  0.,  4.,  0.,  0.,  0.,  0.],\n",
       "       [ 3., 49.,  5.,  3.,  0.,  5.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  9., 47.,  8.,  4., 10.,  0.,  0.,  0.,  0.],\n",
       "       [ 3., 11.,  8., 45.,  7.,  6.,  2.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  4.,  7.,  9.,  0.,  1.,  0.,  2.,  0.],\n",
       "       [ 0.,  5.,  5.,  1.,  0., 29.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., 32.,  1.,  2.,  4.],\n",
       "       [ 0.,  0.,  1.,  0.,  1.,  2.,  5., 25.,  4.,  2.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  6.,  2., 21., 10.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  4., 59.]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('train')\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "conf_mat_train = np.zeros((len(classes)-1,len(classes)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    \n",
    "    # get the data compute fuzzy labels\n",
    "    X = batch_dict['x_data']\n",
    "\n",
    "    y_target = batch_dict['y_target']\n",
    "    y_fuzzy = batch_dict['y_fuzzy']\n",
    "\n",
    "    Y = compute_fuzzy_label(y_target, y_fuzzy, fuzzy= args.fuzzy, \n",
    "                            how=args.fuzzy_how, lbd = args.fuzzy_lambda)\n",
    "\n",
    "    # compute the output\n",
    "    y_pred = classifier(X)\n",
    "    \n",
    "    conf_mat_train = np.add(conf_mat_train,confusion_matrix(y_target.argmax(axis=1), y_pred.argmax(axis=1),\n",
    "                                                            labels=range(len(classes)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250.,  17.,   8.,  47.,   1.,   5.,   2.,   0.,   0.,   0.],\n",
       "       [  9., 525.,  11.,  53.,   7.,  22.,   1.,   0.,   0.,   0.],\n",
       "       [  7.,  37., 456.,  56.,   7.,  77.,   1.,   2.,   1.,   1.],\n",
       "       [ 23., 112.,  37., 565.,  13.,  18.,   2.,   0.,   0.,   0.],\n",
       "       [  0.,   8.,  15.,  34., 139.,   5.,   3.,   1.,   2.,   0.],\n",
       "       [  4.,  21.,  23.,   2.,   2., 271.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   2.,   1., 344.,  12.,   9.,  14.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   3.,  31., 212.,  12.,   2.],\n",
       "       [  0.,   0.,   1.,   0.,   1.,   0.,  23.,   5., 277.,  62.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   8.,   0.,  39., 518.]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(conf_mat_test),pd.DataFrame(conf_mat_val),pd.DataFrame(conf_mat_train)],axis=1).to_csv(args.save_dir+'confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(conf_mat_test),pd.DataFrame(conf_mat_val),pd.DataFrame(conf_mat_train)],axis=1).to_csv(args.save_dir+'baseline_confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_metrics(confusion_matrix, classes):\n",
    "    '''\n",
    "    Compute the per class precision, recall, and F1 for all the classes\n",
    "    \n",
    "    Args:\n",
    "    confusion_matrix (np.ndarry) with shape of (n_classes,n_classes): a confusion matrix of interest\n",
    "    classes (list of str) with shape (n_classes,): The names of classes\n",
    "    \n",
    "    Returns:\n",
    "    metrics_dict (dictionary): a dictionary that records the per class metrics\n",
    "    '''\n",
    "    num_class = confusion_matrix.shape[0]\n",
    "    metrics_dict = {}\n",
    "    for i in range(num_class):\n",
    "        key = classes[i]\n",
    "        temp_dict = {}\n",
    "        row = confusion_matrix[i,:]\n",
    "        col = confusion_matrix[:,i]\n",
    "        val = confusion_matrix[i,i]\n",
    "        precision = val/row.sum()\n",
    "        recall = val/col.sum()\n",
    "        F1 = 2*(precision*recall)/(precision+recall)\n",
    "        temp_dict['precision'] = precision\n",
    "        temp_dict['recall'] = recall\n",
    "        temp_dict['F1'] = F1\n",
    "        metrics_dict[key] = temp_dict\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "metrics_dict['test'] = per_class_metrics(conf_mat_test, classes[:-1])\n",
    "metrics_dict['val'] = per_class_metrics(conf_mat_val, classes[:-1])\n",
    "metrics_dict['train'] = per_class_metrics(conf_mat_train, classes[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict({(i,j): metrics_dict[i][j] \n",
    "                           for i in metrics_dict.keys() \n",
    "                           for j in metrics_dict[i].keys()},\n",
    "                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(args.save_dir+'per_class_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(args.save_dir+'baseline_per_class_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on totally Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ouv_csv='Data/sd_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jac_k_accuracy(y_pred, y_target, k=3, multilabel=False):\n",
    "    \n",
    "    y_pred_indices = y_pred.topk(k, dim=1)[1]\n",
    "    y_target_indices = y_target.topk(k, dim=1)[1]\n",
    "        \n",
    "    n_correct = torch.tensor([torch.tensor([y_pred_indices[j][i] in y_target_indices[j] for i in range(k)]).sum()>0 \n",
    "                              for j in range(len(y_pred))]).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "\n",
    "def compute_jac_1_accuracy(y_pred, y_target, k=3, multilabel=False):\n",
    "    \n",
    "    y_pred_indices = y_pred.topk(1, dim=1)[1]\n",
    "    y_target_indices = y_target.topk(k, dim=1)[1]\n",
    "        \n",
    "    n_correct = torch.tensor([torch.tensor([y_pred_indices[j] in y_target_indices[j] for i in range(k)]).sum()>0 \n",
    "                              for j in range(len(y_pred))]).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 2.251692771911621\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    loss_func = cross_entropy\n",
    "    set_seed_everywhere(args.seed, args.cuda)\n",
    "    train_state = make_train_state(args)\n",
    "    dataset = OuvDataset.load_dataset_and_load_vectorizer(new_ouv_csv, args.vectorizer_file)\n",
    "\n",
    "    dataset.set_split('val')\n",
    "    verbose=False\n",
    "    try:\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_1_acc = 0.0\n",
    "        running_k_acc = 0.0\n",
    "        running_k_jac = 0.0\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # step 2. get the data compute fuzzy labels\n",
    "            X = batch_dict['x_data']\n",
    "\n",
    "            y_target = batch_dict['y_target']\n",
    "            y_fuzzy = batch_dict['y_fuzzy']\n",
    "\n",
    "            Y = compute_fuzzy_label(y_target, y_fuzzy, fuzzy= args.fuzzy, \n",
    "                                    how=args.fuzzy_how, lbd = args.fuzzy_lambda)\n",
    "\n",
    "            # step 3. compute the output\n",
    "            y_pred = classifier(X)\n",
    "\n",
    "            # step 4. compute the loss\n",
    "            loss = loss_func(y_pred, Y)\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracies\n",
    "            acc_1_t = compute_jac_1_accuracy(y_pred, y_target)\n",
    "            acc_k_t = compute_jac_k_accuracy(y_pred, y_target, args.k)\n",
    "            jac_k_t = compute_jaccard_index(y_pred, y_target, len(classes))\n",
    "\n",
    "            running_1_acc += (acc_1_t - running_1_acc) / (batch_index + 1)\n",
    "            running_k_acc += (acc_k_t - running_k_acc) / (batch_index + 1)\n",
    "            running_k_jac += (jac_k_t - running_k_jac) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            if verbose:\n",
    "                val_bar.set_postfix(loss=running_loss, \n",
    "                                acc_1=running_1_acc,\n",
    "                                acc_k=running_k_acc,\n",
    "                                jac_k=running_k_jac,\n",
    "                                epoch=epoch_index)\n",
    "                val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_1_acc'].append(running_1_acc)\n",
    "        train_state['val_k_acc'].append(running_k_acc)\n",
    "        train_state['val_k_jac'].append(running_k_jac)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Exiting loop\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_k_acc_val': 0,\n",
       " 'learning_rate': 0.0005,\n",
       " 'epoch_index': 0,\n",
       " 'train_loss': [],\n",
       " 'train_1_acc': [],\n",
       " 'train_k_acc': [],\n",
       " 'train_k_jac': [],\n",
       " 'val_loss': [2.5796218200244025],\n",
       " 'val_1_acc': [66.14583333333331],\n",
       " 'val_k_acc': [94.14062499999999],\n",
       " 'val_k_jac': [0.3468318094809849],\n",
       " 'test_loss': -1,\n",
       " 'test_1_acc': -1,\n",
       " 'test_k_acc': -1,\n",
       " 'test_k_jac': -1,\n",
       " 'model_filename': 'model_storage/boe/model.pth'}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LS Model\n",
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_k_acc_val': 0,\n",
       " 'learning_rate': 0.0005,\n",
       " 'epoch_index': 0,\n",
       " 'train_loss': [],\n",
       " 'train_1_acc': [],\n",
       " 'train_k_acc': [],\n",
       " 'train_k_jac': [],\n",
       " 'val_loss': [2.8815439714158195],\n",
       " 'val_1_acc': [68.80208333333334],\n",
       " 'val_k_acc': [94.53125000000001],\n",
       " 'val_k_jac': [0.3501152281959852],\n",
       " 'test_loss': -1,\n",
       " 'test_1_acc': -1,\n",
       " 'test_k_acc': -1,\n",
       " 'test_k_jac': -1,\n",
       " 'model_filename': 'model_storage/boe/model.pth'}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
